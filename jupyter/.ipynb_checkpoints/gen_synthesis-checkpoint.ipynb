{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/loitg/workspace/backbone/src/')\n",
    "from utils import Coord, Line\n",
    "from khoi import  transform, ppp\n",
    "from loi import createStandardGrid, multiple_transform, centralize, mls, alignGuidelines, gls2arr,\\\n",
    "drawField, arr1gls, arr2gls, GridMap,reconstructFromField\n",
    "from datagen import syn_augment_matrix, createRandomInfos\n",
    "from tfrecord import arr_feature, value_feature#, writeTfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/loitg/workspace/test_google/')\n",
    "from pbprocess import get_document_bounds, FeatureType, readPb, draw_bounds, bound2points\n",
    "\n",
    "def inputsFromFiles(fn, image_path, pb_path):\n",
    "    image = cv2.imread(os.path.join(image_path, fn))\n",
    "    pb_response = readPb(os.path.join(pb_path, fn.replace('jpg', 'pb') ))\n",
    "    word_bounds = get_document_bounds(pb_response, FeatureType.WORD)\n",
    "    boxes = [bound2points(bound) for bound in word_bounds]\n",
    "    mask_word = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        cv2.fillPoly(mask_word, np.expand_dims(np.array(box, dtype=np.int32), axis=0), 1)\n",
    "        d = Coord(*box[2])-Coord(*box[1]) \n",
    "    mask_fg = np.ones(image.shape[:2], dtype=np.uint8)\n",
    "    return image, mask_word, mask_fg\n",
    "\n",
    "\n",
    "def process(image, mask_word, mask_fg):\n",
    "    infos = createRandomInfos()\n",
    "    xx0, yy0 = createStandardGrid(image.shape)\n",
    "    grid_shape = xx0.shape\n",
    "    xx0 = xx0.reshape(-1)\n",
    "    yy0 = yy0.reshape(-1)\n",
    "    xx1, yy1 = multiple_transform(image, xx0, yy0, infos)\n",
    "    xx1, yy1 = centralize(xx1, yy1)\n",
    "    # Hinh nhan\n",
    "    mapping_infos = GridMap(np.stack([yy0, xx0], axis=1), np.stack([yy1, xx1], axis=1))\n",
    "    mask_words_infos = mapping_infos.transformArrayScalar(mask_word)\n",
    "    mask_fg_infos = mapping_infos.transformArrayScalar(mask_fg)\n",
    "    # foreground, erode\n",
    "    erode_size = int(image.shape[1]/10)\n",
    "    mask_fg_infos = cv2.erode(mask_fg_infos, np.ones((erode_size,erode_size),np.uint8), iterations = 1)[:,:,np.newaxis]\n",
    "    image_infos = mapping_infos.transformArrayScalar_bilinear(image)\n",
    "    \n",
    "    # GLS lam phang => deviation field\n",
    "    gls = arr2gls(yy1, xx1, grid_shape)\n",
    "    a_gls = alignGuidelines(gls)\n",
    "    control_points = gls2arr(gls) #to_array2([item for sublist in gls for item in sublist])\n",
    "    dst_points = gls2arr(a_gls) #to_array2([item for sublist in a_gls for item in sublist])\n",
    "    mapping_align = GridMap(control_points, dst_points)\n",
    "    deviation_field = mapping_align.deviationFromShape(image_infos.shape)\n",
    "\n",
    "    return image_infos,deviation_field, mask_words_infos, mask_fg_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fakeJpeg(arr, max_value=None):\n",
    "    if max_value is None:\n",
    "        arr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650000000970875.2dd3731c-184a-4fbe-bc8b-e1333a732e72.636613902329249130.jpg\n",
      "init writer\n",
      "1.9052009582519531\n",
      "8.873725652694702\n",
      "0\n",
      "650000000099701.6f548839-56fa-4bd8-b580-b404ca274d23.636617521901894950.jpg\n",
      "1.9864623546600342\n",
      "9.352935791015625\n",
      "1\n",
      "650000000560544.074ef820-8069-4a0c-a1a4-e0555b605607.636615554955395590.jpg\n",
      "2.134333610534668\n",
      "10.436185598373413\n",
      "2\n",
      "650000000945170.ae71c488-564f-435d-92a6-bbd88725b14d.636613201821177483.jpg\n",
      "2.6353793144226074\n",
      "14.518974781036377\n",
      "3\n",
      "650000000606618.52fedb0d-8a5e-4b31-a2da-ecb120dea247.636615873344159482.jpg\n",
      "close writer\n",
      "init writer\n",
      "2.384410858154297\n",
      "11.1717369556427\n",
      "4\n",
      "650000000101322.bf965fd5-1a62-4fe5-b802-b5778a4f7d6d.636616409110973771.jpg\n",
      "2.253582239151001\n",
      "11.710733890533447\n",
      "5\n",
      "650000000185615.6b0bd0f3-e033-484a-a3ab-ffa1e6d167ee.636612946165540619.jpg\n",
      "2.2253026962280273\n",
      "10.305992364883423\n",
      "6\n",
      "650000000249771.3f52a9d6-ac7a-45a0-bad7-28859168c6ce.636611283254296381.jpg\n",
      "2.1186516284942627\n",
      "9.47851276397705\n",
      "7\n",
      "650000000153634.30bba01d-822f-490f-9d75-ed3b6df27b8d.636614794756285098.jpg\n",
      "close writer\n",
      "init writer\n",
      "2.0025768280029297\n",
      "9.596300840377808\n",
      "8\n",
      "650000000045145.88c9bf58-0447-4802-897b-89c733f1bd7d.636611255110597804.jpg\n",
      "2.104607105255127\n",
      "9.830069541931152\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "pbin = '/home/loitg/ssd/data/temp3/protobuf_unify_old'\n",
    "hinhphang1 = '/home/loitg/workspace/dewarp/hinhphang1'\n",
    "imagestemp = '/home/loitg/workspace/backbone/imagestemp/'\n",
    "    \n",
    "from scipy import stats\n",
    "from time import time\n",
    "\n",
    "\n",
    "for i, fn in enumerate(os.listdir(hinhphang1)[:10]):\n",
    "#     if fn not in ['650000000945170.ae71c488-564f-435d-92a6-bbd88725b14d.636613201821177483.jpg']:\n",
    "#         continue\n",
    "    print(fn)\n",
    "\n",
    "    tt = time()\n",
    "    image, mask_word, mask_fg = inputsFromFiles(fn,hinhphang1, pbin)\n",
    "    new_image, deviation_field, new_mask, new_fg = process(image, mask_word, mask_fg)\n",
    "    print(time()-tt)\n",
    "    tt = time()\n",
    "\n",
    "    for j in range(4):\n",
    "        t, r = syn_augment_matrix(image, None, None)\n",
    "        aug_image = t.transform_image(new_image)\n",
    "        aug_mask = t.transform_image(new_mask)[:,:,np.newaxis]\n",
    "        aug_fg = t.transform_image(new_fg)[:,:,np.newaxis]\n",
    "        aug_field = t.transform_field(deviation_field)\n",
    "        aug_image = image*(aug_fg < 0.5) + aug_image*(aug_fg >= 0.5)\n",
    "           \n",
    "#         cv2.imwrite(os.path.join(imagestemp, '%d_%d_%s_folded.jpg' % (i,j,fn)), aug_image)\n",
    "#         cv2.imwrite(os.path.join(imagestemp, '%d_%d_%s_fg.jpg' % (i,j,fn)), aug_fg*255)\n",
    "\n",
    "\n",
    "#         reconstructed = reconstructFromField(aug_image, aug_field)\n",
    "#         cv2.imwrite(os.path.join(imagestemp, '%d_%d_%s_recons.jpg' % (i,j,fn)), reconstructed)\n",
    "    print(time()-tt)\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.io.TFRecordWriter('/home/loitg/workspace/backbone/temp/a.tfrecord') as writer:\n",
    "#     for i in range(2):\n",
    "#          writeTfrecord(writer, img, field, fg, words)\n",
    "#         writer.write(eg.SerializeToString())\n",
    "        \n",
    "# filenames = ['/home/loitg/workspace/backbone/temp/a.tfrecord']\n",
    "# raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "# # Create a description of the features.\n",
    "# feature_description = {\n",
    "#     'width': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "#     'height': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "#     'img': tf.io.VarLenFeature(tf.int64),\n",
    "#     'fg': tf.io.VarLenFeature(tf.float32),\n",
    "#     'field': tf.io.VarLenFeature(tf.float32),\n",
    "# }\n",
    "\n",
    "# def _restore_dim(flatten, width, height, channel):\n",
    "#     bb = tf.sparse.to_dense(flatten, default_value=0)\n",
    "#     return tf.reshape(bb,(height,width,channel))\n",
    "\n",
    "# def _parse_function(example_proto):\n",
    "#     parsed_record = tf.io.parse_single_example(example_proto, feature_description)\n",
    "#     width = parsed_record['width']\n",
    "#     height = parsed_record['height']\n",
    "#     parsed_record['img'] = _restore_dim(parsed_record['img'], width, height, 3)\n",
    "#     parsed_record['fg'] = _restore_dim(parsed_record['fg'], width, height, 1)\n",
    "#     parsed_record['field'] = _restore_dim(parsed_record['field'], width, height, 2)\n",
    "#     return parsed_record\n",
    "\n",
    "# parsed_dataset = raw_dataset.map(_parse_function)\n",
    "# parsed_dataset\n",
    "\n",
    "\n",
    "# for parsed_record in raw_dataset.take(1):\n",
    "#     b = tf.io.parse_single_example(parsed_record, feature_description)\n",
    "#     print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# writer = None\n",
    "#         writeTfrecord(writer, aug_image, aug_field, aug_fg, aug_mask)\n",
    "# writer.close()\n",
    "\n",
    "\n",
    "#     if i%4 == 0:\n",
    "#         if writer is not None:\n",
    "#             writer.close()\n",
    "#             print('close writer')\n",
    "#         writer = tf.io.TFRecordWriter('/home/loitg/workspace/backbone/temp/a_%d.tfrecord' % (i//4))\n",
    "#         print('init writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(213, 320, 3), dtype=uint8, numpy=\n",
       "array([[[194, 206, 218],\n",
       "        [194, 206, 218],\n",
       "        [194, 206, 218],\n",
       "        ...,\n",
       "        [169, 190, 207],\n",
       "        [162, 184, 205],\n",
       "        [158, 180, 204]],\n",
       "\n",
       "       [[195, 207, 219],\n",
       "        [195, 207, 219],\n",
       "        [195, 207, 219],\n",
       "        ...,\n",
       "        [170, 191, 208],\n",
       "        [162, 184, 205],\n",
       "        [155, 179, 203]],\n",
       "\n",
       "       [[196, 208, 220],\n",
       "        [196, 208, 220],\n",
       "        [196, 208, 220],\n",
       "        ...,\n",
       "        [170, 191, 208],\n",
       "        [161, 183, 206],\n",
       "        [154, 178, 202]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[232, 237, 241],\n",
       "        [234, 239, 243],\n",
       "        [236, 241, 245],\n",
       "        ...,\n",
       "        [211, 220, 229],\n",
       "        [213, 222, 229],\n",
       "        [202, 211, 216]],\n",
       "\n",
       "       [[234, 239, 242],\n",
       "        [236, 241, 244],\n",
       "        [238, 243, 246],\n",
       "        ...,\n",
       "        [217, 226, 235],\n",
       "        [221, 230, 235],\n",
       "        [212, 221, 226]],\n",
       "\n",
       "       [[235, 240, 243],\n",
       "        [237, 242, 245],\n",
       "        [239, 244, 247],\n",
       "        ...,\n",
       "        [221, 230, 237],\n",
       "        [229, 238, 243],\n",
       "        [223, 233, 235]]], dtype=uint8)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_string = open(cat_in_snow, 'rb').read()\n",
    "type(image_string)\n",
    "tf.image.decode_jpeg(image_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
